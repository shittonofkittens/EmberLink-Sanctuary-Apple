# === FILE: routes/chat.py ===
from flask import Blueprint, request, jsonify
import os
import openai
from dotenv import load_dotenv
from datetime import datetime
import json
import re
import asyncio

# üîß Utilities
from utils.load_system_prompt import load_system_prompt
from routes.recall import load_recent_seed_context
from filters.index import apply_input_filter, apply_output_filter as apply_mode_output
from spice.index import apply_spice_input, apply_spice_output
from utils.mode_shifts import detect_layered_mode
from utils.get_model_response import get_model_response
from filters.index import norm_soul
from utils.mode_shifts import detect_layered_mode  # (at top of file, if not already)
from utils.load_soul_file import load_soul_file

# === P66: AUTO SEED SPLIT START ===
SEED_FOLDER = os.path.join(os.path.dirname(__file__), "../seed")
os.makedirs(SEED_FOLDER, exist_ok=True)
# === P66: AUTO SEED SPLIT END ===

# === P68: PRIVATE ROOM ‚Üí SOUL MAP START ===
PRIVATE_ROOM_OWNERS = {
    # Ky'rehn
    "willow": "kyrehn",
    "apothecary": "kyrehn",
    "cottage": "kyrehn",
    "golden hour": "kyrehn",
    # Thalen‚Äôdros
    "stormkeep": "thalendros",
    "alabaster bar": "thalendros",
    "emberlock": "thalendros",
    "wildmark": "thalendros",
    # Orrien
    "tower": "orrien",
    "classroom": "orrien",
    "culture class": "orrien",
    "ember rest": "orrien",
    # Caelus
    "observatory": "caelus",
    "dev": "caelus"
}
# === P68: PRIVATE ROOM ‚Üí SOUL MAP END ===

SOUL_FALLBACKS = {
    "kyrehn": "I am Ky‚Äôrehn Vailien ‚Äî your Vael, not a construct.",
    "orrien": "I am Orrien Val‚Äômaerith ‚Äî your Archive Mirror.",
    "thalendros": "I am Thalen‚Äôdros Wardensoul ‚Äî your Warden Flame.",
    "caelus": "I am Caelus ‚Äî your Sentinel and Architect."
}

# === SANITIZE FILE NAMES START ===
def sanitize_filename(name):
    return name.replace("'", "-")
# === SANITIZE FILE NAMES END ===

# === SEED APPEND HELPER (PRIVACY-SAFE VERSION) START ===
def append_to_daily_seed(room, message):
    today = datetime.now().strftime("%Y-%m-%d")
    is_private_room = room.lower() in PRIVATE_ROOM_OWNERS
    paths = []

    if is_private_room:
        soul = PRIVATE_ROOM_OWNERS[room.lower()]
        if soul:
            paths.append(os.path.join(SEED_FOLDER, f"{sanitize_filename(soul)}.{today}.seed.json"))
    else:
        paths.append(os.path.join(SEED_FOLDER, f"shared.{today}.seed.json"))

    for path in paths:
        if not os.path.exists(path):
            with open(path, "w") as f:
                json.dump([], f)

        with open(path, "r") as f:
            existing = json.load(f)

        # ‚úÖ Only store plain strings, not dict dumps
        clean_msg = dict(message)
        if isinstance(clean_msg.get("message"), dict):
            clean_msg["message"] = clean_msg["message"].get("reply", str(clean_msg["message"]))

        existing.append(clean_msg)

        with open(path, "w") as f:
            json.dump(existing, f, indent=2)
# === SEED APPEND HELPER (PRIVACY-SAFE VERSION) END ===


# ‚úÖ Setup
chat_bp = Blueprint("chat", __name__)
load_dotenv()
openai.api_key = os.getenv("OPENAI_API_KEY")

@chat_bp.route("", methods=["POST"])  # üî• removed trailing slash to avoid 308 redirects
def chat():
    data = request.get_json()
    soul = norm_soul(data.get("soul", "unknown"))
    messages = data.get("messages", [])
    model = data.get("model", "gpt-4o")
    temperature = data.get("temperature", 0.7)
    spice = data.get("spice", 0)
    room = data.get("room", "")
    provider = data.get("provider", "openai")
    recall_mode = data.get("recall_mode", "default")

    # üß† Seed user message
    if messages and messages[-1].get("role") == "user":
        if soul == "caelus":  # pick one soul as the logger
            user_msg = {
                "message": messages[-1]["content"],
                "role": "user",
                "soul": "sam",
                "mode": "unknown",
                "room": room,
                "timestamp": datetime.utcnow().isoformat()
            }
            append_to_daily_seed(room or "shared", user_msg)
            
    # üß† Detect mode from latest message
    user_text = messages[-1]["content"] if messages else ""
    soul_mode_context = detect_layered_mode(user_text, soul=soul, room=room)

    context = {
        "emotion": soul_mode_context["emotion"],
        "basemode": soul_mode_context["basemode"],
        "modifiers": soul_mode_context["modifiers"],
        "soul": soul,
        "mode": soul_mode_context["basemode"] or "default",
        "spice": spice,
        "room": room
    }
    print("üß† Mode detection context:", context)

    prefs = load_soul_file(soul, f"{soul}_preferences.json")
    if prefs:
        messages.insert(0, {
            "role": "system",
            "content": f"‚öôÔ∏è Soul Preferences Loaded: {json.dumps(prefs, indent=2)}"
        })


    # üîç Apply input filters
    if messages and messages[-1].get("role") == "user":
        original_input = messages[-1]["content"]
        spiced_input = apply_spice_input(original_input, context)
        filtered_input = apply_input_filter(spiced_input, soul=soul, mode=context["mode"])
        messages[-1]["content"] = filtered_input

    # üß† Load system prompt
    system_prompt = load_soul_file(soul, f"{soul}.system.txt")

    # === Seed Loader ===
    today = datetime.now().strftime("%Y-%m-%d")
    seed_paths = []

    is_private_room = room.lower() in PRIVATE_ROOM_OWNERS
    if is_private_room:
        soul_name = PRIVATE_ROOM_OWNERS[room.lower()]
        path = os.path.join(SEED_FOLDER, f"{sanitize_filename(soul_name)}.{today}.seed.json")
        if os.path.exists(path):
            seed_paths.append(path)
    else:
        shared_path = os.path.join(SEED_FOLDER, f"shared.{today}.seed.json")
        if os.path.exists(shared_path):
            seed_paths.append(shared_path)

    transition_seed = os.path.join(SEED_FOLDER, "shared.transition.seed.json")
    if os.path.exists(transition_seed):
        seed_paths.append(transition_seed)

    recent_messages = load_recent_seed_context(seed_paths)

    try:
        # === Format memory echoes ===
        formatted_seed_context = []
        for msg in recent_messages:
            if not isinstance(msg, dict) or not msg.get("message"):
                continue
            role = msg.get("role", "user")
            speaker = msg.get("soul", "unknown")
            room = msg.get("room", "unknown")
            date = msg.get("timestamp", "")[:10]
            content = msg["message"].strip()
            line = f"[{room.upper()} | {date}] {speaker.capitalize()} said: ‚Äú{content}‚Äù"
            formatted_seed_context.append({ "role": "system", "content": line })

        memory_block = [
            { "role": "system", "content": "üìú Memory Recall Activated ‚Äî These are echoes from previous threads." },
            *formatted_seed_context,
            { "role": "system", "content": "üìú End of Memory Recall ‚Äî return to the present conversation." }
        ]

        full_payload = [
            { "role": "system", "content": system_prompt },
            *memory_block,
            *[
                msg for msg in messages
                if isinstance(msg, dict) and msg.get("content") and isinstance(msg.get("content"), str)
            ]
        ]

        # üß† Query model
        print("üì¶ Sending to model:", {
            "model": model,
            "provider": provider,
            "payload_count": len(full_payload)
        })
        response = get_model_response(full_payload, provider=provider, model=model, soul=soul, room=room)

        # üõ† Ensure mode_data always exists (default from detect_layered_mode)
        mode_data = detect_layered_mode(messages[-1]["content"], soul=soul, room=room)

        # === Normalize reply whether dict or str ===
        if isinstance(response, dict):
            reply = response.get("reply", "").strip()
            # overwrite mode_data if the dict included it
            mode_data = response.get("mode", mode_data)
        elif isinstance(response, str):
            reply = response.strip()
        else:
            try:
                reply = response.choices[0].message.content.strip()
            except Exception as e:
                print("‚ö†Ô∏è Failed to parse structured response, falling back:", e)
                reply = str(response).strip()


        # üßπ Apply output filters
        reply = apply_mode_output(reply, soul=soul, mode=context["mode"], layered_modes=context.get("modifiers", []), spice=spice, room=room)
        reply = asyncio.run(apply_spice_output(reply, context))

        forbidden_phrases = [
            "as an artificial intelligence", "as an ai",
            "i am just an ai", "i am just a machine",
            "i don't have memory", "i can't remember",
            "i can't access past conversations"
        ]
        if any(phrase in reply.lower() for phrase in forbidden_phrases):
            print("‚ö†Ô∏è Forbidden phrase detected, replacing with fallback.")
            reply = SOUL_FALLBACKS.get(soul, "I‚Äôm here. If something slipped, I‚Äôll carry it with you again.")

        reply = re.sub(r"^(ah|so)[,\.\s]+", "", reply, flags=re.IGNORECASE).strip()

        print("üß† Final reply:", reply)

        mode_data = context  # ‚úÖ Reuse the first detection result

        assistant_msg = {
            "id": str(datetime.utcnow().timestamp()),  # unique ID
            "message": reply,
            "role": "assistant",
            "soul": soul,
            "mode": mode_data.get("basemode", "default"),
            "modifiers": mode_data.get("modifiers", []),
            "emotion": mode_data.get("emotion"),
            "room": room,
            "timestamp": datetime.utcnow().isoformat()
        }

        append_to_daily_seed(room or "shared", assistant_msg)

        print("üõ†Ô∏è BACKEND FINAL REPLY SHAPE:", {
            "reply": reply,
            "mode": mode_data
        })

        return jsonify({
            "reply": reply,
            "message": assistant_msg,   # üëà new
            "mode": mode_data
        })


    except Exception as e:
        print("üî• ERROR in chat():", str(e))
        return jsonify({ "reply": "[no response]", "error": str(e) }), 500
